{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Activation, Dropout, Flatten\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.datasets import cifar10\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # 使用 CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 539430479022924295, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 3188470579\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 18139284467487079018\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 10\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_class)\n",
    "y_test = keras.utils.to_categorical(y_test, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== EarlyStop =======\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== ModelCheckPoint ========\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(filepath='./resnet_cifar10.h5', monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== ResNet50 ============\n",
    "model = ResNet50(input_shape=(32,32,3), weights='imagenet', pooling='max', include_top=False)\n",
    "\n",
    "res_featuremap = model.output\n",
    "# flatten_featuremap = Flatten()(res_featuremap)\n",
    "output = Dense(units=num_class, activation='softmax')(res_featuremap)\n",
    "\n",
    "model = keras.models.Model(input=[model.input], output=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 18s 2ms/step\n",
      "loss:  0.7219919486045837\n",
      "accuracy:  0.7684999704360962\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('./resnet_cifar10.h5')\n",
    "loss_loadback, acc_loadback = model.evaluate(x_test, y_test)\n",
    "print('loss: ', loss_loadback)\n",
    "print('accuracy: ', acc_loadback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=keras.optimizers.Adam(), \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 建立 ImageDataGenerator，並指定我們要做資料增強的數值範圍\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "390/390 [==============================] - 174s 447ms/step - loss: 0.5795 - accuracy: 0.7984 - val_loss: 0.6849 - val_accuracy: 0.7654\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.65802\n",
      "Epoch 2/15\n",
      "390/390 [==============================] - 181s 465ms/step - loss: 0.5525 - accuracy: 0.8083 - val_loss: 0.7878 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.65802\n",
      "Epoch 3/15\n",
      "390/390 [==============================] - 184s 471ms/step - loss: 0.5677 - accuracy: 0.8037 - val_loss: 0.5937 - val_accuracy: 0.7999\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65802 to 0.59372, saving model to ./resnet_cifar10.h5\n",
      "Epoch 4/15\n",
      "390/390 [==============================] - 184s 473ms/step - loss: 0.5750 - accuracy: 0.8022 - val_loss: 1.1759 - val_accuracy: 0.7173\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.59372\n",
      "Epoch 5/15\n",
      "390/390 [==============================] - 185s 474ms/step - loss: 0.5357 - accuracy: 0.8157 - val_loss: 0.6540 - val_accuracy: 0.7843\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.59372\n",
      "Epoch 6/15\n",
      "390/390 [==============================] - 183s 469ms/step - loss: 0.4881 - accuracy: 0.8300 - val_loss: 0.6776 - val_accuracy: 0.7731\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.59372\n",
      "Epoch 7/15\n",
      "390/390 [==============================] - 187s 481ms/step - loss: 0.4809 - accuracy: 0.8335 - val_loss: 0.6011 - val_accuracy: 0.8052\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.59372\n",
      "Epoch 8/15\n",
      "390/390 [==============================] - 187s 479ms/step - loss: 0.4618 - accuracy: 0.8380 - val_loss: 0.8123 - val_accuracy: 0.7446\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.59372\n",
      "Epoch 9/15\n",
      "390/390 [==============================] - 185s 474ms/step - loss: 0.4547 - accuracy: 0.8416 - val_loss: 0.7746 - val_accuracy: 0.7529\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.59372\n",
      "Epoch 10/15\n",
      "390/390 [==============================] - 186s 476ms/step - loss: 0.4451 - accuracy: 0.8435 - val_loss: 0.5963 - val_accuracy: 0.7988\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.59372\n",
      "Epoch 11/15\n",
      "390/390 [==============================] - 187s 480ms/step - loss: 0.4296 - accuracy: 0.8521 - val_loss: 0.6074 - val_accuracy: 0.8046\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.59372\n",
      "Epoch 12/15\n",
      "390/390 [==============================] - 189s 484ms/step - loss: 0.4322 - accuracy: 0.8488 - val_loss: 0.8775 - val_accuracy: 0.7389\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.59372\n",
      "Epoch 13/15\n",
      "390/390 [==============================] - 189s 484ms/step - loss: 0.4174 - accuracy: 0.8549 - val_loss: 0.5847 - val_accuracy: 0.8072\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.59372 to 0.58475, saving model to ./resnet_cifar10.h5\n",
      "Epoch 14/15\n",
      "390/390 [==============================] - 189s 484ms/step - loss: 0.4987 - accuracy: 0.8297 - val_loss: 0.6117 - val_accuracy: 0.8060\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.58475\n",
      "Epoch 15/15\n",
      "390/390 [==============================] - 186s 476ms/step - loss: 0.4010 - accuracy: 0.8591 - val_loss: 0.6702 - val_accuracy: 0.7846\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.58475\n",
      "loss:  0.6702034020423889\n",
      "accuracy:  0.784600019454956\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(data_generator.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "                    steps_per_epoch=int(len(x_train)/BATCH_SIZE),\n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpoint],\n",
    "                    shuffle=True)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('loss: ', scores[0])\n",
    "print('accuracy: ', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 16s 2ms/step\n",
      "loss:  0.584746712398529\n",
      "accuracy:  0.807200014591217\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('./resnet_cifar10.h5')\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print('loss: ', loss)\n",
    "print('accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
